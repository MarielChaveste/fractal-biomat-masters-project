{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cd4715f-7a3c-4640-ae77-8472704d74db",
   "metadata": {},
   "source": [
    "# Calculadora de dimensiones a partir de coordenadas almacenadas en .txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17e655f9-af19-4ef3-bf87-c8c56323a17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def leer_coordenadas(ruta_txt):\n",
    "    \"\"\"\n",
    "    Lee las coordenadas desde un archivo .txt y las devuelve como un array de NumPy.\n",
    "    \n",
    "    Args:\n",
    "        ruta_txt (str): Ruta al archivo de coordenadas .txt.\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: Array de coordenadas (x, y).\n",
    "    \"\"\"\n",
    "    coordenadas = []\n",
    "    with open(ruta_txt, 'r') as f:\n",
    "        for line in f:\n",
    "            x, y = map(float, line.strip().split(','))\n",
    "            coordenadas.append((x, y))\n",
    "    return np.array(coordenadas)\n",
    "\n",
    "def calcular_dimension_correlation_incremental(coordenadas, radio_min=0.1, radio_max=10.0, num_radios=100, num_pares=100000):\n",
    "    \"\"\"\n",
    "    Calcula la dimensión de correlación usando el método de Grassberger-Procaccia con muestreo incremental.\n",
    "    \n",
    "    Args:\n",
    "        coordenadas (np.ndarray): Array de coordenadas (x, y).\n",
    "        radio_min (float): Radio mínimo.\n",
    "        radio_max (float): Radio máximo.\n",
    "        num_radios (int): Número de radios a considerar entre el mínimo y el máximo.\n",
    "        num_pares (int): Número de pares de puntos a muestrear aleatoriamente.\n",
    "        \n",
    "    Returns:\n",
    "        float: Dimensión de correlación estimada.\n",
    "    \"\"\"\n",
    "    radios = np.logspace(np.log10(radio_min), np.log10(radio_max), num=num_radios)\n",
    "    conteos = np.zeros(num_radios)\n",
    "\n",
    "    for _ in range(num_pares):\n",
    "        idx1, idx2 = random.sample(range(len(coordenadas)), 2)\n",
    "        distancia = np.linalg.norm(coordenadas[idx1] - coordenadas[idx2])\n",
    "        \n",
    "        for i, radio in enumerate(radios):\n",
    "            if distancia < radio:\n",
    "                conteos[i] += 1\n",
    "                break\n",
    "\n",
    "    conteos = conteos / num_pares\n",
    "    log_radios = np.log(radios)\n",
    "    log_conteos = np.log(conteos + 1e-10)  # Avoid log(0)\n",
    "\n",
    "    coef = np.polyfit(log_radios, log_conteos, 1)\n",
    "    dimension_correlation = coef[0]\n",
    "\n",
    "    return dimension_correlation\n",
    "\n",
    "def procesar_archivos_y_guardar_dimensiones(ruta_carpeta):\n",
    "    \"\"\"\n",
    "    Procesa todos los archivos de coordenadas en una carpeta, calcula la dimensión de correlación\n",
    "    para cada archivo y guarda los resultados en 'correlation_dimentions.tsv'.\n",
    "    \n",
    "    Args:\n",
    "        ruta_carpeta (str): Carpeta que contiene los archivos de coordenadas.\n",
    "    \"\"\"\n",
    "    ruta_tsv = 'correlation_dimentions.tsv'  # Nombre del archivo de salida\n",
    "\n",
    "    # Leer IDs ya procesados\n",
    "    if os.path.exists(ruta_tsv):\n",
    "        with open(ruta_tsv, 'r') as f_in:\n",
    "            processed_ids = {line.split('\\t')[0] for line in f_in.readlines()[1:]}  # Ignorar encabezado\n",
    "    else:\n",
    "        processed_ids = set()\n",
    "\n",
    "    with open(ruta_tsv, 'a') as f_out:  # Abrir en modo 'append' para no sobrescribir\n",
    "        if not processed_ids:  # Escribir encabezado solo si el archivo está vacío\n",
    "            f_out.write(\"ID\\tCorrelation_Dimension\\n\")\n",
    "\n",
    "        for filename in os.listdir(ruta_carpeta):\n",
    "            if filename.endswith('.txt'):\n",
    "                sample_id = os.path.splitext(filename)[0]\n",
    "\n",
    "                # Saltar si ya ha sido procesado\n",
    "                if sample_id in processed_ids:\n",
    "                    print(f\"Saltado: {sample_id}, ya procesado.\")\n",
    "                    continue\n",
    "                \n",
    "                print(f\"Procesando: {sample_id}\")\n",
    "                ruta_txt = os.path.join(ruta_carpeta, filename)\n",
    "                coordenadas = leer_coordenadas(ruta_txt)\n",
    "\n",
    "                # Saltar archivos con menos de dos coordenadas\n",
    "                if len(coordenadas) < 2:\n",
    "                    print(f\"Ignorado: {sample_id}, datos insuficientes.\")\n",
    "                    continue\n",
    "                \n",
    "                dimension_correlation = calcular_dimension_correlation_incremental(coordenadas)\n",
    "                \n",
    "                # Escribir el nombre del archivo (sin extensión) y su dimensión de correlación en el archivo .tsv\n",
    "                f_out.write(f\"{sample_id}\\t{dimension_correlation}\\n\")\n",
    "                print(f\"Procesado: {sample_id} con dimensión de correlación {dimension_correlation}\")\n",
    "            else:\n",
    "                print(f\"Ignorado: {filename}, no es un archivo .txt válido.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb64ca67-ce71-4ae7-a7a1-c143698cd4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Ejemplo\n",
    "path_input_folder = \"/files/Mariel/Tesis_Mariel/data/Examples\"\n",
    "array_dimension = procesar_archivos_y_guardar_dimensiones(path_input_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "umap",
   "language": "python",
   "name": "umap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
